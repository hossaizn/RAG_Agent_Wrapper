# QueryGenie: RAG-Powered Conversational AI
This is an AI chatbot that combines Cohere’s AI with real-time data retrieval from external APIs. It is built using FastAPI for the backend and Streamlit for the frontend.

## Features
- Uses Retrieval-Augmented Generation (RAG) to provide more accurate and context-aware responses.
- Retrieves live data from APIs such as Wikipedia, OpenFDA, Alpha Vantage, and Open Library.
- Maintains conversation history, allowing for more natural multi-turn interactions.
- Built with FastAPI for the backend and Streamlit for the user interface.

## Demo
To see how this chatbot works, check out the screenshots below:



## Tech Stack
- AI Model: Cohere API
- Backend: FastAPI
- Frontend: Streamlit
- APIs Integrated:
  - OpenFDA (for drug information)
  - Alpha Vantage (for stock prices)
  - Wikipedia (for general knowledge)
  - Open Library (for book searches)

## How to Run the Project
Follow these steps to set up the project on your local machine.

### Step 1: Clone the Repository
First, download the project to your computer:

git clone https://github.com/your-username/querygenie-rag-chatbot.git
cd querygenie-rag-chatbot

### Step 2: Install Necessary Packages
Make sure you have Python installed. Then, install the required packages:
pip install -r requirements.txt

### Step 3: Run the backend server
python3 -m uvicorn main:app --host 127.0.0.1 --port 8002 --reload

Once the server is running, you can access the API documentation here:
http://127.0.0.1:8002/docs

### Step 4: Start the Chatbot UI
In a new terminal window, start the chatbot UI:
streamlit run app.py


## How It Works
- The user sends a query, such as "Tell me about aspirin" or "Stock price of Tesla."
- The chatbot detects intent and extracts entities using spaCy.
- If needed, the chatbot fetches real-world data from external APIs.
- The final response is generated using:
-   API data (if available).
-   AI-generated text via Cohere API (if the API doesn’t return relevant data).
- The response is displayed in the chat interface, and conversation history is stored.


## Example Queries to Try

# AI Response (Generated by Cohere)
- "Tell me about Python."
- "Explain AI in simple terms."

# API Response (Live Data)
- "Stock price of Apple?"
- "Tell me about aspirin."
- "Find a book on Data Science."


## The codebase is structured as follows:
querygenie-rag-chatbot
│-- api
│   |-- nlp          # NLP-related utilities
│   |-- integrations # API integrations
│-- config           # Stores API keys securely
│-- app.py           # Streamlit frontend
│-- main.py          # FastAPI backend
│-- requirements.txt # List of dependencies
│-- README.md        # Project documentation


## Future Improvements
- Add a vector database to store API responses and improve retrieval efficiency.
- Deploy the project online so users can test it without installing anything.
- Expand the API integrations to include more industries (e.g., legal, weather, news).